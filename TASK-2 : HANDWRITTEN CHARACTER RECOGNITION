# -*- coding: utf-8 -*-
"""Copy of emnist-letters_cnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M8E7OYRJ-R7Rw_JxjHhExkC_7OJlBDTr
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %reload_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import datetime
import time
import os
import matplotlib.pyplot as plt
import numpy as np
from keras.callbacks import TensorBoard
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU, AveragePooling2D

# https://www.tensorflow.org/guide/keras/overview
import tensorflow as tf

# https://www.tensorflow.org/datasets
import tensorflow_datasets as tfds

# https://www.tensorflow.org/datasets/catalog/emnist
(ds_train, ds_test), ds_info = tfds.load('emnist/letters', split=['train', 'test'], shuffle_files=True, as_supervised=True, with_info=True)
print(ds_info)

# https://www.tensorflow.org/datasets/keras_example

def normalize_img(image, label):
  """Normalizes images: `uint8` -> `float32`."""
  return tf.cast(image, tf.float32) / 255., label

ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
ds_train = ds_train.cache()
ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)
ds_train = ds_train.batch(128)
ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)



ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
ds_test = ds_test.batch(128)
ds_test = ds_test.cache()
ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs
model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(filters=473, kernel_size= (3, 3), activation=tf.nn.relu, input_shape=(28,28,1)),
  tf.keras.layers.AveragePooling2D((2, 2)),
  tf.keras.layers.Dropout(rate=0.15),
  tf.keras.layers.Conv2D(filters=238, kernel_size= (3, 3), padding='valid', activation=tf.nn.leaky_relu),
  tf.keras.layers.BatchNormalization(),
  #tf.keras.layers.MaxPooling2D((2, 2)),
  tf.keras.layers.Dropout(rate=0.20),
  tf.keras.layers.Conv2D(filters=133, kernel_size= (3, 3), activation=tf.nn.relu),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Dropout(rate=0.10),
  tf.keras.layers.Conv2D(filters=387, kernel_size= (3, 3), activation=tf.nn.relu),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Dropout(rate=0.10),
  tf.keras.layers.Conv2D(filters=187, kernel_size= (5, 5), activation=tf.nn.elu),
  tf.keras.layers.Dropout(rate=0.50),
  #tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(313, activation=tf.nn.relu),
  tf.keras.layers.BatchNormalization(),
  #tf.keras.layers.Dense(512, activation=tf.nn.relu),
  tf.keras.layers.Dropout(rate=0.20),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(252, activation=tf.nn.elu),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Dropout(rate=0.20),
  # tf.keras.layers.Flatten(),
  #tf.keras.layers.Dense(128,activation=tf.nn.relu),
  #tf.keras.layers.BatchNormalization(),
  #tf.keras.layers.Dropout(rate=0.5),
  tf.keras.layers.Dense(37, activation=tf.nn.softmax)
  #tf.keras.layers.Dense(37, activation=tf.nn.softmax)
])
model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer=tf.keras.optimizers.RMSprop(),
    metrics=['accuracy'],
)
#logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir="logs/{}".format(time()))
tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=0,
                          write_graph=True, write_images=False)

history = model.fit(
    ds_train,
    epochs=20,
    validation_data=ds_test, callbacks=[tensorboard_callback]
)
score = model.evaluate(ds_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1]*100, "%")


#tf.summary.image(ds_test, max_outputs=2, step=0)

#predicted_classes = model.predict_classes(ds_test)

# We may need to do the long version of this:
#incorrect_indices = np.nonzero(predicted_classes != ds_test.reshape((-1,)))[0]

#incorrect_indices = 0
# Need iterate over ds_test.as_numpy_iterator()
#for value in ds_test.as_numpy_iterator():
  # value should be a NumPy array of features and predictions (?)
    #np.incorrect_indices[1]
  # if so, reshape the array to grab the prediction from the end, and compare to the corresponding element of predicted_classes
  # if they're not equal, increment incorrect_indices


# print(len(incorrect_indices)," classified incorrectly")

# #adapt figure size to accomodate 18 subplots
# plt.rcParams['figure.figsize'] = (7,14)

# figure_evaluation = plt.figure()

# #plot 9 incorrect predictions
# for i, incorrect in enumerate(incorrect_indices[:9]):
#     plt.subplot(3,3,i+1)
#     plt.imshow(ds_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')
#     plt.title(
#       "Predicted {}, Truth: {}".format(predicted_classes[incorrect],
#                                        ds_test[incorrect]))
#     plt.xticks([])
#     plt.yticks([])

# Commented out IPython magic to ensure Python compatibility.
# def plot_features(features, transpose=False):
#   print(features['label'].numpy())
#   image = features['image'][1]
#   if transpose:
#     image = tf.transpose(image)
#   plt.imshow(image)

# plot_features(list(ds_train.take(1))[0])
# Sets up a timestamped log directory.
# logdir = "logs/train_data/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
# # Creates a file writer for the log directory.
# file_writer = tf.summary.create_file_writer(logdir)
# with file_writer.as_default():
#   # Don't forget to reshape.
#   images = np.reshape(ds_test[0:25], (-1, 28, 28, 1))
#   tf.summary.image("25 training data examples", images, max_outputs=25, step=0)

# %tensorboard --logdir logs/train_data

# emnist_example = tfds.as_numpy(ds_test, graph=None)
# for sample in emnist_example:
#     image, label = sample[1], sample[1]
#     plt.imshow(image[1].astype(np.uint8), cmap=plt.get_cmap("gray"))
#     plt.show()
#     print("Label: %d" % label)

# ds = ds_test.take(1)

# for image, label in ds:  # example is (image, label)
#   print(image.shape, label)


ds = ds_test.take(25)
# Sets up a timestamped log directory.
#logdir = "logs/train_data/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
# Creates a file writer for the log directory.
# file_writer = tf.summary.create_file_writer(logdir)

# for image, label in tfds.as_numpy(ds):
#   print(type(image), type(label), label)

#def plot_features(features, transpose=False):
for images, label in tfds.as_numpy(ds):
    #print(features['label'].numpy())
    # image = features['image'][1]
    # Don't forget to reshape.
    images = np.reshape(images[0:25], (-1, 28, 28, 1))
    #print(f'image{images}')
    #pred = model.predict(ds)
    #print(f'predicted indices{pred}')
    #incorrect_indices = np.nonzero(pred != ds)
    #print(f'Incorrect Indices:{incorrect_indices}')
    !rm -rf logs
    logdir = "logs/test"
    #logdir = "logs/train_data/" + datetime.now().strftime("%Y%m%d-%H%M%S")
    file_writer = tf.summary.create_file_writer(logdir)
    with file_writer.as_default():
      tf.summary.image("25 training data examples", images, max_outputs=25, step=0)
  #if transpose:
    #images = tf.transpose(image)


# %tensorboard --logdir logs/test

"""
 My project consisted of trying to figure out how to use the the tensorflow library to import the emnist letters dataset. This dataset just came out. Thank you to Professor Avery for helping me get my program started using this new capability. First, I tried using the different layers given in the original mnist_cnn.py data set that you linked us to. This overall gave me a 92.26% validation accurcracy . Than I tried changing the the kernel size of my convulution neural network to (5, 5). This overall enhanced my end result to  92.43%. I was able to than add another dense layer with 512, which made me get an end result of 92.84&. Than I tried adding Batch Normalization to the end of my laters, the end result was 92.68%. Adding another dropout improved my end result to 92.85%. Adding max pooling some how made by percent go down to 92.35%. I also tried adding max pooling between each convultion neural network, which at the time I only had two. While this proved to be some what helpful overall it brought my percents down. Next, I pushed the drop out to 0.5 in my last drop out layer. This proved to be a great option, my end result was 94.01% percent. With all this being said I have spent hours messing around with my project because it's quite fun at this stage of the project. Keep in mind I was only doing 6 epochs for my testing.

 I have also done some research and looked at a paper that seemed fairly interesting to me. In my project, for my last iteration I have mostly implemented this architecture in order to improve my project. One thing I could not figure out was how to use TReLU with tensorflow. There results seemed to be about 95%. As you can see in my results, my test accurarcy is 94.14%. This overall took more time to run than what I was doing in the above paragraphs. I also increased the number of epochs to 20.

 # Update
 It took me quite a while, but I was able to get tensorboard working. I am still in the process of trying to figure out how to get the missclassified letters. As you can see from a lot of the commented code I have been trying different ways.You will see an output of for images and also epoch graphs.


 Here is the link: https://arxiv.org/pdf/1807.00284.pdf

#How does the accuracy compare to its peformance on MNIST? How does the accuracy compare to the MLP you trained in Project 2?

Obviously the accuracy of the mnist_cnn.py was able to get to 99% at 12 epochs and the MLP in Project 2 was able to get 91%. In my project 3, I am able to get around 94% give or take.

#Recall that EMNIST Letters merges upper- and lowercase letters into the same class, even when they look very different. How might you design a network that accounts for that difference?

To solve this problem I would sum up the total number of classes (i.e. lowercase and uppercase) and than I would make each one of them have a class. Class 1 for lowercase and class 2 for uppercase.

"""

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

from google.colab import files
uploaded = files.upload()

from google.colab import files
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt

# Upload image
uploaded = files.upload()

# Load and preprocess image
image = Image.open("a.jpg").convert("L")  # Convert to grayscale
image = image.resize((28, 28))            # Resize to 28x28
image_array = np.array(image)

# Invert colors if background is white
image_array = 255 - image_array

# Normalize and reshape
image_array = image_array / 255.0
image_array = image_array.reshape(1, 28, 28, 1)

# Visualize the processed image
plt.imshow(image_array[0].reshape(28, 28), cmap='gray')
plt.title("Processed Input Image")
plt.axis('off')
plt.show()

# Predict using your trained model
prediction = model.predict(image_array)
predicted_label = np.argmax(prediction)

# Map to ASCII (A=65)
print("Predicted Character:", chr(predicted_label + 64))

_, image_array = cv2.threshold(image_array, 128, 255, cv2.THRESH_BINARY)

chr(predicted_label + 64)

# Resize, grayscale
image = Image.open("b.jpg").convert("L").resize((28, 28))

# Invert if background is white
image = np.array(image)
image = 255 - image

# Apply binary thresholding
_, image = cv2.threshold(image, 100, 255, cv2.THRESH_BINARY)

# Normalize and reshape
image = image / 255.0
image = image.reshape(1, 28, 28, 1)

from google.colab import files
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt

# Upload image
uploaded = files.upload()

# Load and preprocess image
image = Image.open("z.jpg").convert("L")  # Convert to grayscale
image = image.resize((28, 28))            # Resize to 28x28
image_array = np.array(image)

# Invert colors if background is white
image_array = 255 - image_array

# Normalize and reshape
image_array = image_array / 255.0
image_array = image_array.reshape(1, 28, 28, 1)

# Visualize the processed image
plt.imshow(image_array[0].reshape(28, 28), cmap='gray')
plt.title("Processed Input Image")
plt.axis('off')
plt.show()

# Predict using your trained model
prediction = model.predict(image_array)
predicted_label = np.argmax(prediction)

# Map to ASCII (A=65)
print("Predicted Character:", chr(predicted_label + 64))
